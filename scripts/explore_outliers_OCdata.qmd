---
title: "explore_outliers_OCdata"
author: "Corey Clatterbuck"
format: html
editor: visual
---

## Purpose

Identify potential outliers in ocean conservancy data that may be due to data entry issues. The identified issues (outlined in issue [#5](https://github.com/cclatterbuck/CAplastics/issues/5#issue-1614464765)) so far include:

1.  Large numbers (\>1000) of `People` and `Adults` for some cleanups
2.  Some cleanups include just a single trash item or category, including those with large numbers of people

I wanted to visualize how much data is potentially impacted by these issues to better determine how much data to drop.

## Load data & libraries

Code for accomplishing this is available in the .qmd file.

```{r, include = FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(here)
library(janitor)

oc_raw <- read_excel(here("data", "OceanConservancy_CA.xlsx"), 
                     col_types = c("numeric", "text", "text", "text", "text", 
                                   "text", "date", "text", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric"))
coarse_raw <- read_excel(here("data", "coarse_data_relational_table.xlsx"))
```

## OC data cleanup

Here I reduce OC data to the dates of Coastal Cleanup Day & remove the columns (plastic types) that we do not use -- these are columns that do not include any plastic items or 'pieces' that are not identifiable to a plastic category. The rows are then filtered to remove any cleanups lacking counts for all plastic categories. This last step removes \~1600 cleanups.

The code for accomplishing this is in the .qmd file

```{r, include = FALSE}
ccd_dates <- c("2016-09-17", "2017-09-16", "2018-09-15", "2019-09-21", "2021-09-19")
ccd_dates <- as.Date(ccd_dates)
oc_use <- oc_raw %>%
  mutate(`Cleanup Date` = as.Date(`Cleanup Date`)) %>%
  dplyr::filter(`Cleanup Date` %in% ccd_dates | 
                  (`Cleanup Date` >= as.Date('2020-09-01') & `Cleanup Date` <= as.Date('2020-09-30')))
levels(as.factor(oc_use$`Cleanup Date`)) ## double check

oc_use <- oc_use |>
  dplyr::rename("Fishing Nets" = "Fishing Net & Pieces") |>
  dplyr::select(-ends_with(c("(Clean Swell)", "Pieces", "Collected"))) |>
  dplyr::rename("Fishing Net & Pieces" = "Fishing Nets") |>
  dplyr::filter(!if_all(15:57, is.na))  ## removes ~1600 cleanups
```

## Bin cleanups by people

```{r, echo = FALSE}

# create bins
oc_use |>
  dplyr::mutate(people_bin = cut(People, breaks=c(0, 0.99, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 1000, 10000),
                                 include.lowest = TRUE, right = TRUE,
                                 labels = c("0", "[1, 5]", "[6, 10]", "[11, 20]", 
                                            "[21, 30]", "[31, 40]", "[41, 50]",
                                            "[51, 60]", "[61, 70]", "[71, 80]",
                                            "[81, 90]", "[91, 100]", "[101, 200]",
                                            "[201, 300]", "[301, 400]", "[401, 500]",
                                            "[501, 1000]", "[1001, 10000]"))) |>
  # group_by(people_bin) |>
  # summarize(n = n()) |>
  ggplot(aes(x = people_bin)) +
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), vjust=-1) +
  scale_y_continuous(limits = c(0,6000)) +
  xlab("volunteers per cleanup effort") +
  ylab("no. of cleanup efforts") +
  ggtitle("Cleanups binned by # of volunteers") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
```

## How many cleanups have more people than collected items?

And potentially, what bin do these groups fall in?

```{r, echo = FALSE}
# remove cleanups with more people than items collected
oc_test <- oc_use |>
  dplyr::mutate(total_collected = rowSums(across(15:57), na.rm = TRUE),
                ratio_collected = round(total_collected/People, 4)) |>
  relocate(ratio_collected, .after = People) |>
  dplyr::filter(ratio_collected < 0.9999)


# plot
oc_test |>
  dplyr::mutate(people_bin = cut(People, breaks=c(0, 0.99, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 1000, 10000),
                                 include.lowest = TRUE, right = TRUE,
                                 labels = c("0", "[1, 5]", "[6, 10]", "[11, 20]", 
                                            "[21, 30]", "[31, 40]", "[41, 50]",
                                            "[51, 60]", "[61, 70]", "[71, 80]",
                                            "[81, 90]", "[91, 100]", "[101, 200]",
                                            "[201, 300]", "[301, 400]", "[401, 500]",
                                            "[501, 1000]", "[1001, 10000]"))) |>
  # group_by(people_bin) |>
  # summarize(n = n()) |>
  ggplot(aes(x = people_bin)) +
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), vjust=-1) +
  scale_y_continuous(limits = c(0,100)) +
  xlab("volunteers per cleanup effort") +
  ylab("no. of cleanup efforts") +
  ggtitle("Cleanups where volunteers outnumber collected items") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

While most of these cleanups were in groups of few people, note that 13 of 16 cleanups occurring in the \[1001, 10000\] bin also had a item:people ratio \< 1. All item:people ratios less than 1 total 163 cleanups, which is \~2.5% of the data filtered to this point.

For reference, here is a plot of the collected item:people ratios for the remaining data. I remove cleanups where people = 0 in the code chunk as well because `cut` doesn't play nicely with infinite numbers. Note the binned intervals change on the x-axis as we move from left to right.

```{r, echo = FALSE}
oc_test2 <- oc_use |>
  dplyr::mutate(total_collected = rowSums(across(15:57), na.rm = TRUE),
                ratio_collected = round(total_collected/People, 4)) |>
  relocate(ratio_collected, .after = People) |>
  dplyr::filter(ratio_collected > 0.9999) |>
  dplyr::filter(is.finite(ratio_collected)) ## don't know why I couldn't put these two filter calls together, but it didn't run correctly.

oc_test2 |>
  dplyr::mutate(ratio_bin = cut(ratio_collected, breaks=c(1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 250, 500, 1000, 4000),
                                 include.lowest = TRUE
                                 # labels = c("[1, 5]", "[5, 10]", "[11, 15]", 
                                 #            "[16, 20]", "[31, 40]", "[41, 50]",
                                 #            "[51, 60]", "[61, 70]", "[71, 80]",
                                 #            "[81, 90]", "[91, 100]", "[101, 200]",
                                 #            "[201, 300]", "[301, 400]", "[401, 500]",
                                 #            "[501, 1000]", "[1001, 10000]")
                                )) |>
  ggplot(aes(x = ratio_bin)) +
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), vjust=-1) +
  scale_y_continuous(limits = c(0,800)) +
  xlab("bins of collected item:volunteer ratio") +
  ylab("no. of cleanup efforts") +
  ggtitle("Cleanups where collected items outnumber volunteers") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Summary

After filtering the OC data to Coastal Cleanup Day dates, we have **8143** cleanups. This was completed in previous scripts but wanted to include here as well.

-   Remove unidentifiable plastic categories & reduce to cleanups with identifiable items only: -1614, **6529**
-   Remove cleanups where volunteers outnumber collected items: -162, **6367**
-   Remove cleanups with 0 people, as you cannot account for effort: -7, **6360 cleanups**

Here's a breakdown of the number of cleanups by year -- note that there are many more cleanups for 2020 as the whole month of September was labeled "Coastal Cleanup Month", rather than a single day, due to the COVID pandemic. Also, 2021's data is incomplete. It would be good to get an updated dataset for 2021-2022 if easy for OC folks to accomplish.

```{r, echo = FALSE}
oc_test2 |>
  dplyr::mutate(Year = year(`Cleanup Date`)) |> ## fails?
ggplot(aes(x = Year)) +
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), vjust=-1) +
  scale_y_continuous(limits = c(0,3000)) +
  xlab("Year") +
  ylab("No. of cleanup efforts") +
  ggtitle("No. of Cleanup Efforts, 2016-2021") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Code to clean raw OC data

The code below can be used to load & clean the ocean conservancy data from the raw file:

```{r}
library(tidyverse)
library(lubridate)
library(readxl)
library(here)
library(janitor)

oc_raw <- read_excel(here("data", "OceanConservancy_CA.xlsx"), 
                     col_types = c("numeric", "text", "text", "text", "text", 
                                   "text", "date", "text", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric",
                                   "numeric", "numeric", "numeric", "numeric", "numeric"))

## reduce dates
ccd_dates <- c("2016-09-17", "2017-09-16", "2018-09-15", "2019-09-21", "2021-09-19")
ccd_dates <- as.Date(ccd_dates)
oc_use <- oc_raw %>%
  mutate(`Cleanup Date` = as.Date(`Cleanup Date`)) %>%
  dplyr::filter(`Cleanup Date` %in% ccd_dates | 
                  (`Cleanup Date` >= as.Date('2020-09-01') & `Cleanup Date` <= as.Date('2020-09-30')))
levels(as.factor(oc_use$`Cleanup Date`)) ## double check

## remove unidentifiable pieces
oc_use <- oc_use |>
  dplyr::rename("Fishing Nets" = "Fishing Net & Pieces") |>
  dplyr::select(-ends_with(c("(Clean Swell)", "Pieces", "Collected"))) |>
  dplyr::rename("Fishing Net & Pieces" = "Fishing Nets") |>
  dplyr::filter(!if_all(15:57, is.na))  ## removes ~1600 cleanups

## remove collected item:people ratio less than one, as well as 0s. Remove cols use to calculate these, if desired 
oc_use <- oc_use |>
  dplyr::mutate(total_collected = rowSums(across(15:57), na.rm = TRUE),
                ratio_collected = round(total_collected/People, 4)) |>
  relocate(ratio_collected, .after = People) |>
  dplyr::filter(ratio_collected > 0.9999) |>
  dplyr::filter(is.finite(ratio_collected)) |>
  dplyr::select(-total_collected, -ratio_collected)
```

## Statistical examination of outliers

Per [Issue 6](https://github.com/cclatterbuck/CAplastics/issues/6), I want to examine distribution boxplots for cleanup data from all accumulated plastics as well as per plastic type. I suspect a transformation will be needed for some plastic types, as some types will have 0s for multiple cleanups. I may also want to create tables with the results of normality tests, per [this source](https://www.e-education.psu.edu/geog586/node/678).

To do so, I first need to get the cleanup item categories into the coarse categories used for the later analysis -- that is, I need to pull in coarse_data_relational_table.xlsx, join, and remove data without a coarse name (these are typically non-plastic items). The results are two data frames where each row is a cleanup: one with counts (oc_coarse_counts), and one with normalized counts (oc_coarse_norm).

```{r}
## load relational table
coarse_raw <- read_excel(here("data", "coarse_data_relational_table.xlsx"))

## subset relational table for unique oc plastic items only
coarse_oc <- coarse_raw |>
  dplyr::select(oc_name, used_coarse_name) |>
  distinct() |>
  dplyr::filter(!is.na(oc_name))

## make oc data long & join coarse names 
## NOTE: this does include take out/away containers as a separate category
colnames(oc_use)
oc_long <- oc_use %>%
  dplyr::select(1,2,7,9,11,15:57) %>% ## keep columns to help calculate effort later
  remove_empty(which = "rows") %>%
  pivot_longer(!c("Cleanup ID", "Zone", "Adults", "People", "Cleanup Date"), names_to = "Item", values_to = "Count") %>%
  left_join(coarse_oc, by = c("Item" = "oc_name"))

## make cleanup categories as coarse categories & normalize
oc_long |> dplyr::filter(is.na(used_coarse_name)) |> distinct(Item) |> print(n=25)
oc_coarse_counts <- oc_long |> 
  dplyr::filter(!is.na(used_coarse_name)) |>
  group_by(`Cleanup ID`, used_coarse_name) |> ## sum within cleanup id and used_coarse_name
  summarise(sums = sum(Count, na.rm=TRUE)) |>
  pivot_wider(names_from = used_coarse_name, values_from = sums) |>
  left_join(oc_use |> dplyr::select(`Cleanup ID`, Zone, `Cleanup Date`, People, Adults), by = "Cleanup ID") |>
  relocate(c("Cleanup ID", "Zone", "Cleanup Date", "People", "Adults"), .after = "Cleanup ID") |>
  mutate(totals=sum(c_across(appliances:toys), na.rm = TRUE))
oc_coarse_norm <- oc_coarse_counts |>
  mutate_at(vars(appliances:totals),~./People) |>
  mutate_at(vars(appliances:totals), round, 3)
```
